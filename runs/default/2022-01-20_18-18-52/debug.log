2022-01-20 18:18:52   Arguments: Namespace(upscale_input=False, downscale_input=False, augment_input='None', backbone='resnet18', use_netvlad=True, netvlad_clusters=64, use_gem=None, gem_p=3, gem_eps=1e-06, use_attention='cbam', attention_lr=0.01, use_sgd=None, use_adagrad=None, momentum=0.9, train_batch_size=4, infer_batch_size=16, margin=0.1, epochs_num=20, patience=3, lr=1e-05, cache_refresh_rate=1000, queries_per_epoch=5000, negs_num_per_query=10, neg_samples_num=1000, seed=0, device='cuda', num_workers=8, val_positive_dist_threshold=25, train_positives_dist_threshold=10, recall_values=[1, 5, 10, 20], datasets_folder='./Dataset_pitts30k', exp_name='default', test_dataset_name=None, test_model_path=None, save_attention_mask=None, output_folder='runs/default/2022-01-20_18-18-52')
2022-01-20 18:18:52   The outputs are being saved in runs/default/2022-01-20_18-18-52
2022-01-20 18:18:52   Using 1 GPUs and 12 CPUs
2022-01-20 18:18:52   Loading dataset Pitts30k from folder ./Dataset_pitts30k
2022-01-20 18:18:52   There are 96 queries without any positives within the training set. They won't be considered as they're useless for training.
2022-01-20 18:18:52   Train query set: < TripletsDataset, pitts30k - #database: 10000; #queries: 7320 >
2022-01-20 18:18:52   Val set: < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >
2022-01-20 18:18:53   Test set: < BaseDataset, pitts30k - #database: 10000; #queries: 6816 >
2022-01-20 18:18:53   Train only conv4 of the ResNet-18 (remove conv5), freeze the previous ones
2022-01-20 18:18:58   Output dimension of the model is 16384
2022-01-20 18:18:58   Start training epoch: 00
2022-01-20 18:18:58   Cache: 0 / 5
2022-01-20 18:21:58   Epoch[00](0/5): current batch triplet loss = 0.0312, average epoch triplet loss = 0.0320
2022-01-20 18:21:58   Cache: 1 / 5
2022-01-20 18:24:58   Epoch[00](1/5): current batch triplet loss = 0.0399, average epoch triplet loss = 0.0304
2022-01-20 18:24:58   Cache: 2 / 5
2022-01-20 18:27:57   Epoch[00](2/5): current batch triplet loss = 0.0133, average epoch triplet loss = 0.0290
2022-01-20 18:27:57   Cache: 3 / 5
2022-01-20 18:30:56   Epoch[00](3/5): current batch triplet loss = 0.0370, average epoch triplet loss = 0.0280
2022-01-20 18:30:56   Cache: 4 / 5
